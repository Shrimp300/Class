from __future__ import print_function

import numpy as np
import pandas as pd

from sklearn.neural_network import MLPClassifier
from sklearn import metrics
from sklearn import model_selection
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import Binarizer

class DummyScaler:
    
    def fit(self, data):
        pass
    
    def transform(self, data):
        return data

def create_scaler_dummy():
    return DummyScaler()
    
def create_scaler_standard():
    return StandardScaler()

def create_scaler_minmax():
    return MinMaxScaler()

def crete_scaler_binarizer():
    return Binarizer()

# You can choose a scaler (just one should be uncommented):
# create_scaler = create_scaler_dummy
create_scaler = create_scaler_standard
# create_scaler = create_scaler_minmax
# create_scaler = create_scaler_binarizer


seed = 520
np.set_printoptions(precision=3)
model = MLPClassifier(hidden_layer_sizes=(10,10,10), random_state=seed)

print('Load the data')
myfile = r"\Users\Norris\Onedrive\IEE520\project 1\Avila.csv"
data = pd.read_csv(myfile)
print(data.describe())

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
data_transform = data.apply(le.fit_transform)


# Need to convert as yhat returned by the code is numpy
# Otherwise, we input one Dataframe and one numpy array to the confusion matrix
# and this will cause calculation error
data_transform = data_transform.to_numpy()

X = data_transform[:, 0:10]
y = data_transform[:, 10]

# Count of each target values in the dataset
tgt_values, unique_counts = np.unique(y,return_counts=True)
print(list(zip(tgt_values, unique_counts)))

print('Features:')
print(X)


print('Targets:')
print(y)


print('Train the model and predict')
scaler = create_scaler()
model.fit(X, y)
y_hat = model.predict(X)


print('Model evaluation (train)')
print('Accuracy:')
print(metrics.accuracy_score(y, y_hat))
print('Classification report:')
print(metrics.classification_report(y, y_hat))


print('Confusion matrix (train)')

print('Confusion matrix')
df = pd.DataFrame({'y_Actual':y, 'y_Predicted':y_hat})
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])
print (confusion_matrix)


print('Cross-validation')
np.random.seed(seed)
y_prob = np.zeros(y.shape)
y_hat = np.zeros(y.shape)

kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=seed)

# Cross-validation
for train, test in kfold.split(X, y):
    # Train classifier on training data, predict test data
    
    # Scaling train and test data
    # Train scaler on training set only
    scaler.fit(X[train])
    X_train = scaler.transform(X[train])
    X_test = scaler.transform(X[test])
    model.fit(X_train, y[train])
    y_prob[test] = model.predict_proba(X_test)[:,1]
    y_hat[test] = model.predict(X_test)


print('Model evaluation (CV)')
print('Accuracy:')
print(metrics.accuracy_score(y, y_hat))
print('Classification report:')
print(metrics.classification_report(y, y_hat))


# print('Confusion matrix (CV)')
print('Confusion matrix')
df = pd.DataFrame({'y_Actual':y, 'y_Predicted':y_hat})
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])
print (confusion_matrix)


# cm.print_stats()
# ax = cm.plot(backend='seaborn', annot=True, fmt='g')
# ax.set_title('Confusion Matrix (CV)')
# plt.show()


# print('ROC curve')

# ROC curve code here is for 2 classes only
# if len(np.unique(y)) == 2: 
#     fpr, tpr, threshold = metrics.roc_curve(y, y_prob)
#     roc_auc = metrics.auc(fpr, tpr)
#     plt.title('Receiver Operating Characteristic')
#     plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)
#     plt.legend(loc='lower right')
#     plt.plot([0, 1], [0, 1], 'r--')
#     plt.xlim([-0.01, 1.01])
#     plt.ylim([-0.01, 1.01])
#     plt.ylabel('True Positive Rate')
#     plt.xlabel('False Positive Rate')
#     plt.show()
