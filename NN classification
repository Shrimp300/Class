import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.neural_network import MLPClassifier
from sklearn import metrics
from sklearn import model_selection
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import Binarizer


'''Pick 1'''
create_scaler = StandardScaler()
# create_scaler = MinMaxScaler()
# create_scaler = Binarizer()


seed = 520
np.set_printoptions(precision=3)
model = MLPClassifier(max_iter = 1500, hidden_layer_sizes=(10,60,60,60,60,), random_state=seed, tol=1e-2, n_iter_no_change = 5)

#Load data
myfile = r"\Users\Norris\Onedrive\IEE520\project 1\Avila.csv"
data = pd.read_csv(myfile)
print('Data Details')
print(data.describe())

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
data_transform = data.apply(le.fit_transform)


data_transform = data_transform.to_numpy()

X = data_transform[:, 0:-1]
y = data_transform[:, -1]

# Count of each target values in the dataset
tgt_values, unique_counts = np.unique(y,return_counts=True)
print(list(zip(tgt_values, unique_counts)))

print('Features:')
print(X)


print('Targets:')
print(y)


print('Train the model and predict')
scaler = create_scaler
model.fit(X, y)
y_hat = model.predict(X)


print('Model evaluation (train)')
print('Accuracy:')
print(metrics.accuracy_score(y, y_hat))
print('Classification report:')
print(metrics.classification_report(y, y_hat))


print('Confusion matrix (train)')

print('Confusion matrix')
df = pd.DataFrame({'y_Actual':y, 'y_Predicted':y_hat})
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])
print (confusion_matrix)


print('Cross-validation')
np.random.seed(seed)
y_prob = np.zeros(y.shape)
y_hat = np.zeros(y.shape)

kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=seed)

# Cross-validation
for train, test in kfold.split(X, y):
    scaler.fit(X[train])
    X_train = scaler.transform(X[train])
    X_test = scaler.transform(X[test])
    model.fit(X_train, y[train])
    y_prob[test] = model.predict_proba(X_test)[:,1]
    y_hat[test] = model.predict(X_test)


print('Model evaluation (CV)')
print('Accuracy:')
print(metrics.accuracy_score(y, y_hat))
print('Classification report:')
print(metrics.classification_report(y, y_hat))


# print('Confusion matrix (CV)')
print('Confusion matrix')
df = pd.DataFrame({'y_Actual':y, 'y_Predicted':y_hat})
confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])
print (confusion_matrix)


print('ROC curve')
# ROC curve code here is for 2 classes only
if len(np.unique(y)) == 10: 
     fpr, tpr, threshold = metrics.roc_curve(y, y_prob)
     roc_auc = metrics.auc(fpr, tpr)
     plt.title('Receiver Operating Characteristic')
     plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)
     plt.legend(loc='lower right')
     plt.plot([0, 1], [0, 1], 'r--')
     plt.xlim([-0.01, 1.01])
     plt.ylim([-0.01, 1.01])
     plt.ylabel('True Positive Rate')
     plt.xlabel('False Positive Rate')
     plt.show()
